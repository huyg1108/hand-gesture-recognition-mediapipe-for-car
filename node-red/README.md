# ğŸš— Hand Gesture Car Control System
## *Complete IoT Solution vá»›i Node-RED Dashboard + ThingSpeak Analytics*

## ğŸ“‹ Tá»•ng quan há»‡ thá»‘ng:

Há»‡ thá»‘ng Ä‘iá»u khiá»ƒn xe báº±ng cá»­ chá»‰ tay hoÃ n chá»‰nh vá»›i real-time monitoring, cloud analytics vÃ  comprehensive logging:

```
[Hand Gesture App] â†’ [MQTT] â†’ [Node-RED Dashboard] â†’ [ThingSpeak Cloud]
       â†“                â†“            â†“                    â†“
   MediaPipe       broker.hivemq    Web Interface      Analytics
   Recognition     .com:1883        Dashboard          Storage
```

### **ğŸ¯ Core Technologies:**
- **ğŸ–ï¸ MediaPipe** - Hand gesture recognition vá»›i AI
- **ğŸ“¡ MQTT** - Real-time communication protocol  
- **ğŸ›ï¸ Node-RED** - Visual flow programming + dashboard
- **â˜ï¸ ThingSpeak** - Cloud analytics & visualization
- **ğŸ“Š Real-time Monitoring** - System health tracking

## âœ¨ TÃ­nh nÄƒng ná»•i báº­t:

### **ğŸ® Gesture Control:**
- **5 Gestures**: â¬†ï¸Forward, â¬‡ï¸Backward, â¬…ï¸Left, â¡ï¸Right, ğŸ›‘Stop
- **AI Recognition**: MediaPipe vá»›i confidence threshold
- **Stability Check**: Anti-jitter vá»›i gesture buffering
- **Unknown Gesture**: Auto-stop sau 2 giÃ¢y

### **ğŸ“Š Dashboard Components:**
- **Car Controls**: 5 gesture buttons + manual override
- **Command Logs**: Real-time sent/received commands
- **System Status**: Raspberry Pi health monitoring
- **Error Monitoring**: Comprehensive error tracking
- **Log Management**: Clear logs + auto-cleanup

### **ğŸ“¡ MQTT Topics Structure:**
```
raspi/hcmus/car/gesture        # Gesture commands
raspi/hcmus/car/log/system     # System lifecycle 
raspi/hcmus/car/log/webcam     # Camera status
raspi/hcmus/car/log/wifi       # Network connectivity
```

### **â˜ï¸ ThingSpeak Integration (3-Field):**
- **Field 1**: Severity Level (1=Low, 2=Medium, 3=High)
- **Field 2**: Combined Error Message
- **Field 3**: ISO Timestamp
- **Rate Limiting**: 15-second intervals
- **Auto-Upload**: Critical errors only

### **ğŸ›¡ï¸ System Monitoring:**
- **Raspberry Pi Status**: Camera + WiFi + System health
- **Error Detection**: Keyword-based error categorization
- **Offline Resilience**: Local backup + recovery
- **Graceful Shutdown**: Comprehensive cleanup notifications

## ğŸš€ Quick Start Guide:

### **Step 1: Setup Node-RED**
```bash
# Install Node-RED globally
npm install -g node-red

# Install required nodes
npm install -g node-red-dashboard

# Start Node-RED server
node-red
```

### **Step 2: Import Dashboard Flow**
```bash
# 1. Open Node-RED: http://localhost:1880
# 2. Menu (â˜°) â†’ Import â†’ Upload file
# 3. Select: final-complete-flow.json
# 4. Click "Deploy" button
# 5. Success! âœ…
```

### **Step 3: Access Dashboard**
```bash
# Dashboard URL:
http://localhost:1880/ui

# Expected: Complete car control interface
```

### **Step 4: Run Hand Gesture App**
```bash
cd hand-gesture-recognition-mediapipe-for-car

# Install dependencies
pip install -r requirements.txt

# Run with MQTT enabled
python app.py --enable_mqtt

# Expected: Camera opens + MQTT connection
```

## ğŸ“Š Dashboard Layout:

```
ğŸš— Car Control Dashboard
â”‚
â”œâ”€â”€ ğŸ® Car Controls
â”‚   â”œâ”€â”€ â¬†ï¸ Forward  â¬‡ï¸ Backward  â¬…ï¸ Left  â¡ï¸ Right  ğŸ›‘ Stop
â”‚   â””â”€â”€ ğŸ—‘ï¸ Clear All Logs
â”‚
â”œâ”€â”€ ğŸ“‹ Command Logs  
â”‚   â”œâ”€â”€ ğŸ“¤ Sent Commands     â”‚ ğŸ“¥ Received Commands
â”‚   â””â”€â”€ [Real-time display]  â”‚ [MQTT subscriber logs]
â”‚
â”œâ”€â”€ ğŸ“ System Status (Raspberry Pi Monitoring)
â”‚   â”œâ”€â”€ ğŸ“¹ Camera: âœ… Active / âŒ Error
â”‚   â”œâ”€â”€ ğŸ“¶ WiFi: âœ… Connected / âŒ Disconnected  
â”‚   â”œâ”€â”€ ğŸ•’ Last Update: [Timestamp]
â”‚   â””â”€â”€ ğŸ“‹ Recent System Logs (6 latest entries)
â”‚
â””â”€â”€ âš ï¸ Error Monitoring
    â”œâ”€â”€ ï¿½ High Priority Errors
    â”œâ”€â”€ ğŸŸ¡ Medium Priority Warnings
    â”œâ”€â”€ ğŸŸ¢ Low Priority Info
    â””â”€â”€ â˜ï¸ Auto-sync to ThingSpeak
```

## ğŸ”§ Project Structure:

```
AIOT/
â”œâ”€â”€ ğŸ“„ final-complete-flow.json          # â­ Main Node-RED flow (IMPORT THIS)
â”œâ”€â”€ ğŸ“š COMPLETE_SYSTEM_GUIDE.md          # Comprehensive documentation
â”œâ”€â”€ ğŸ§ª test_error_logging.py             # Error scenario testing
â”œâ”€â”€ ğŸ“Š slides_app_logging.md             # Presentation slides
â”œâ”€â”€ ğŸ› ï¸ create_presentation_graphs.py     # Analytics graphs
â”œâ”€â”€ hand-gesture-recognition-mediapipe-for-car/
â”‚   â”œâ”€â”€ ğŸ¯ app.py                        # Main gesture recognition app
â”‚   â”œâ”€â”€ ğŸ“‹ requirements.txt              # Python dependencies
â”‚   â”œâ”€â”€ ğŸ¤– model/                        # AI models directory
â”‚   â”‚   â””â”€â”€ keypoint_classifier/         # Gesture classification model
â”‚   â”œâ”€â”€ ğŸ› ï¸ utils/                        # Utility functions
â”‚   â””â”€â”€ ğŸ“ test_mqtt_receiver.py         # MQTT testing utility
â””â”€â”€ ğŸ“– README.md                         # This comprehensive guide
```

## ğŸ§ª Testing & Validation:

### **ğŸ¯ Test Complete System:**
```bash
# 1. Test Node-RED Dashboard
# Import final-complete-flow.json â†’ Deploy â†’ Open http://localhost:1880/ui
# Expected: All 4 dashboard sections visible and functional

# 2. Test Hand Gesture App
cd hand-gesture-recognition-mediapipe-for-car
python app.py --enable_mqtt
# Expected: Camera opens + MQTT logs in dashboard

# 3. Test Error Scenarios
python test_error_logging.py
# Expected: Error monitoring updates + ThingSpeak data
```

### **ğŸ” Verification Checklist:**
- âœ… **Dashboard responsive**: All buttons work instantly
- âœ… **Real-time logs**: Commands appear immediately  
- âœ… **System monitoring**: Pi status updates correctly
- âœ… **Error detection**: Test errors trigger alerts
- âœ… **ThingSpeak sync**: Critical errors upload to cloud
- âœ… **Gesture recognition**: Hand movements control car
- âœ… **Offline resilience**: Logs saved during disconnection

### **ğŸ“Š Expected Behaviors:**

#### **Normal Operation:**
```
Dashboard: All âœ… green status indicators
Logs: Startup messages â†’ gesture commands â†’ system heartbeat
ThingSpeak: No data (only errors uploaded)
Console: Clean gesture recognition output
```

#### **Error Scenarios:**
```
Camera disconnect â†’ âŒ Camera status â†’ ThingSpeak severity=3
WiFi loss â†’ âŒ WiFi status â†’ Offline log backup
App shutdown â†’ All âŒ status â†’ Graceful cleanup notifications
```

## ï¿½ ThingSpeak Cloud Analytics:

### **ğŸ“ˆ 3-Field Data Structure:**
```javascript
// Optimized for analytics
Field 1: Severity Level    // 1=Low, 2=Medium, 3=High/Critical
Field 2: Error Message     // "[CATEGORY] Description"  
Field 3: ISO Timestamp     // "2025-08-02T10:30:45.123Z"
```

### **ğŸ” Sample Data:**
```json
{
  "field1": 3,                                    // High severity
  "field2": "[CAMERA_ISSUE] Camera disconnected - System shutdown",
  "field3": "2025-08-02T15:30:45.123Z"
}
```

### **ğŸ“Š Analytics Capabilities:**
- **ğŸ“ˆ Severity Trends**: Track error frequency over time
- **ğŸ” Error Categories**: Camera vs WiFi vs System issues  
- **â° Timeline Analysis**: Peak error times identification
- **ğŸ“‹ MATLAB Integration**: Advanced data processing

### **âš™ï¸ Configuration:**
```javascript
// ThingSpeak settings trong Node-RED
API_ENDPOINT: "https://api.thingspeak.com/update"
RATE_LIMIT: 15000ms  // 15-second intervals
AUTO_UPLOAD: Critical errors only (severity >= 2)
```

## ğŸ¤– AI Gesture Recognition:

### **ğŸ–ï¸ Supported Gestures:**
```python
Gesture Classes:
0: Forward    # âœŠ Closed fist
1: Backward   # ğŸ–ï¸ Open palm  
2: Left       # ğŸ‘ˆ Point left
3: Right      # ğŸ‘‰ Point right
4: Stop       # âœ‹ Stop gesture
5: Unknown    # Unrecognized â†’ Auto-stop after 2s
```

### **ğŸ¯ AI Configuration:**
```python
# Performance optimized settings
CONFIDENCE_THRESHOLD = 0.5      # Balance accuracy vs speed
GESTURE_STABILITY = 3           # Require 3 consistent readings
FRAME_SKIP = 1                  # Process every 2nd frame
UNKNOWN_TIMEOUT = 2.0           # Auto-stop after 2 seconds
```

### **ğŸ“¡ MQTT Publishing Logic:**
```python
# Intelligent gesture filtering
1. MediaPipe detection â†’ confidence check
2. Stability buffer â†’ prevent jitter  
3. Change detection â†’ only publish new gestures
4. Unknown handling â†’ timeout safety mechanism
```

## ğŸ›¡ï¸ System Health Monitoring:

### **ğŸ“Š Raspberry Pi Status Tracking:**
- **ğŸ“¹ Camera**: Initialization, disconnection, recovery attempts
- **ğŸ“¶ WiFi**: Connection status, offline backup, reconnection
- **ğŸ–¥ï¸ System**: Startup, heartbeat, graceful shutdown
- **âš ï¸ Errors**: Real-time detection vá»›i keyword analysis

### **ğŸ”„ Recovery Mechanisms:**
```python
Camera Disconnect:
â”œâ”€â”€ 10-second wait period
â”œâ”€â”€ Automatic reconnection attempt  
â”œâ”€â”€ Settings restoration
â””â”€â”€ Failure â†’ Error logging + status update

WiFi Disconnect:
â”œâ”€â”€ Offline log backup to local file
â”œâ”€â”€ Periodic connection checks (5s)
â”œâ”€â”€ Auto-recovery on reconnection
â””â”€â”€ Batch upload of offline logs
```

### **ğŸš¨ Error Categories:**
- **ğŸ”´ High**: System shutdown, camera failure, critical errors
- **ğŸŸ¡ Medium**: Network timeouts, video stream interrupts  
- **ğŸŸ¢ Low**: Info messages, successful operations

## ğŸ¯ Success Indicators:

### **âœ… Dashboard Working:**
```
âœ“ All 4 sections visible and responsive
âœ“ Buttons trigger immediate command logs  
âœ“ System status shows real-time Pi health
âœ“ Error monitoring displays categorized alerts
âœ“ Clear logs function resets all displays
âœ“ No page refresh required for updates
```

### **âœ… MQTT Integration:**
```
âœ“ Connection to broker.hivemq.com:1883
âœ“ Publishing to raspi/hcmus/car/* topics
âœ“ Real-time message flow dashboard â†” app
âœ“ Gesture commands reach car controller
âœ“ System logs update Node-RED displays
```

### **âœ… ThingSpeak Analytics:**
```
âœ“ Critical errors auto-upload (severity â‰¥ 2)
âœ“ 3-field structure: [Severity, Message, Timestamp]
âœ“ Rate limiting respected (15-second intervals)
âœ“ Data visible in ThingSpeak channel
âœ“ Analytics charts available for trends
```

### **âœ… AI Gesture Recognition:**
```
âœ“ MediaPipe hand detection active
âœ“ 5 gesture classes recognized accurately
âœ“ Stability filtering prevents false triggers
âœ“ Unknown gestures safely timeout to Stop
âœ“ MQTT commands reflect hand movements
```

## ğŸš¨ Troubleshooting Guide:

### **ğŸ”§ Dashboard Issues:**

#### **Problem**: Dashboard shows blank page
```bash
Solution:
1. Check Node-RED dashboard installed: npm list -g node-red-dashboard
2. Verify import: Menu â†’ Flows â†’ Check "main_tab" exists
3. Deploy: Red "Deploy" button â†’ Wait for success
4. Refresh browser: Ctrl+F5 or clear cache
```

#### **Problem**: Buttons don't work
```bash
Solution:
1. Check all nodes in same flow tab
2. Verify MQTT node connections (no broken links)
3. Debug: Enable debug nodes â†’ Check console output
4. Re-import final-complete-flow.json if needed
```

### **ğŸ”§ MQTT Connection Issues:**

#### **Problem**: MQTT not connecting
```bash
Solution:
1. Check internet: ping broker.hivemq.com
2. Firewall: Allow port 1883 outbound
3. Test: python test_error_logging.py
4. Verify credentials: No auth required for public broker
```

#### **Problem**: Messages not received
```bash
Solution:
1. Check topic spelling: raspi/hcmus/car/gesture
2. Verify QoS settings: Default 0 in Node-RED
3. Debug MQTT in: Enable output â†’ Check message flow
4. Test with external MQTT client (MQTT Explorer)
```

### **ğŸ”§ Camera/AI Issues:**

#### **Problem**: Camera won't open
```bash
Solution:
1. Check camera permissions: Device Manager â†’ Camera
2. Close other camera apps: Skype, Zoom, etc.
3. Try different device index: --device 1
4. Install OpenCV: pip install opencv-python
```

#### **Problem**: Gestures not recognized
```bash
Solution:
1. Check lighting: Ensure good hand visibility
2. Adjust confidence: Lower --min_detection_confidence
3. Hand positioning: Keep hand in center frame
4. Check model files: model/keypoint_classifier/*.tflite
```

### **ğŸ”§ ThingSpeak Issues:**

#### **Problem**: No data uploading
```bash
Solution:
1. Verify API key in Node-RED ThingSpeak node
2. Check rate limiting: 15s minimum between uploads
3. Test connection: curl ThingSpeak API endpoint
4. Trigger real error: python test_error_logging.py
```

#### **Problem**: Wrong data format
```bash
Solution:
1. Check 3-field structure: [severity, message, timestamp]
2. Verify JSON formatting in Node-RED function
3. Monitor debug console for format errors
4. Update ThingSpeak channel field names
```

## ğŸ‘¨â€ğŸ’» Development & Customization:

### **ğŸ¨ Dashboard Customization:**
```javascript
// Modify button appearance in ui_button nodes
Button Colors: {
  Forward:  "#4CAF50",   // Green
  Backward: "#FF9800",   // Orange  
  Left:     "#2196F3",   // Blue
  Right:    "#9C27B0",   // Purple
  Stop:     "#F44336"    // Red
}

// Update dashboard layout
Group Order: Car Controls(1) â†’ Command Logs(2) â†’ System Status(3) â†’ Error Monitoring(4)
```

### **ğŸ”§ MQTT Customization:**
```javascript
// Change broker/topics trong MQTT nodes
MQTT_BROKER: "your-mqtt-broker.com"
GESTURE_TOPIC: "your/car/gesture"  
LOG_TOPICS: "your/car/log/{system,webcam,wifi}"

// Modify command mappings
Gesture Commands: ["Forward", "Backward", "Left", "Right", "Stop"]
```

### **â˜ï¸ ThingSpeak Customization:**
```javascript
// Update API configuration in ThingSpeak Formatter node
API_KEY: "YOUR_THINGSPEAK_API_KEY"
CHANNEL_ID: your_channel_id
FIELD_MAPPING: {
  field1: severity_level,
  field2: combined_message,
  field3: iso_timestamp
}
```

### **ğŸ¤– AI Model Customization:**
```python
# Update gesture recognition model
Model Path: model/keypoint_classifier/keypoint_classifier.tflite
Label File: model/keypoint_classifier/keypoint_classifier_label.csv

# Retrain vá»›i custom gestures:
1. Collect new gesture data: Modify logging_csv() mode
2. Train model: Use keypoint_classification.ipynb
3. Replace model files: .tflite vÃ  .csv
4. Update gesture count in app.py
```

## ğŸ”— Integration Examples:

### **ğŸš— Physical Car Integration:**
```python
# Add car control hardware interface
import RPi.GPIO as GPIO

def control_car_motors(command):
    if command == "Forward":
        GPIO.output(MOTOR_PIN_1, GPIO.HIGH)
    elif command == "Stop":
        GPIO.output(MOTOR_PIN_1, GPIO.LOW)
    # Add more motor controls...
```

### **ğŸ“± Mobile App Integration:**
```javascript
// Add mobile notifications
const notification_node = {
    "type": "function",
    "func": `
        if (msg.payload.severity >= 2) {
            // Send push notification
            msg.notification = {
                title: "Car Error Alert",
                body: msg.payload.message
            };
        }
        return msg;
    `
}
```

### **ğŸ  Home Automation:**
```javascript
// Integrate vá»›i Home Assistant
const homeassistant_node = {
    "type": "ha-api", 
    "service": "automation.trigger",
    "data": {
        "entity_id": "automation.car_emergency_stop",
        "variables": {
            "error_type": "{{payload.type}}",
            "severity": "{{payload.severity}}"
        }
    }
}
```

## ğŸ“š Additional Resources:

### **ğŸ“– Documentation:**
- **[COMPLETE_SYSTEM_GUIDE.md](COMPLETE_SYSTEM_GUIDE.md)** - Detailed technical documentation
- **[slides_app_logging.md](slides_app_logging.md)** - Presentation slides vá» logging system
- **[Node-RED Documentation](https://nodered.org/docs/)** - Official Node-RED docs
- **[ThingSpeak API Guide](https://thingspeak.com/docs)** - ThingSpeak integration guide

### **ğŸ§ª Testing Tools:**
- **`test_error_logging.py`** - Comprehensive error scenario testing
- **`create_presentation_graphs.py`** - Analytics visualization tools
- **Node-RED Debug Panel** - Real-time flow debugging
- **MQTT Explorer** - External MQTT testing tool

### **ğŸ“ Learning Path:**
1. **Beginner**: Import flow â†’ Test dashboard â†’ Basic customization
2. **Intermediate**: Modify MQTT topics â†’ Custom error handling
3. **Advanced**: AI model training â†’ Hardware integration â†’ Production deployment

## ğŸ† Project Achievements:

### **âœ¨ Technical Highlights:**
- âœ… **Complete IoT stack**: Edge AI â†’ MQTT â†’ Dashboard â†’ Cloud
- âœ… **Production-ready logging**: 4-layer monitoring vá»›i offline backup
- âœ… **Optimized performance**: Frame skipping, gesture stability, rate limiting
- âœ… **Graceful error handling**: Auto-recovery mechanisms
- âœ… **Scalable architecture**: Modular Node-RED flows
- âœ… **Real-time analytics**: ThingSpeak cloud integration

### **ğŸ¯ Perfect for:**
- **ğŸ“ IoT Education**: Complete learning project
- **ğŸš— Autonomous Vehicles**: Gesture control interface
- **ğŸ  Smart Home**: Hand gesture device control  
- **ğŸ­ Industrial Applications**: Touchless machine control
- **â™¿ Accessibility**: Alternative input methods

---

## ğŸš€ **Get Started Now!**

### **âš¡ Quick Deploy (5 minutes):**
```bash
# 1. Clone & setup
git clone [repository]
cd AIOT/node-red

# 2. Start Node-RED  
node-red

# 3. Import flow
# Open: http://localhost:1880
# Import: final-complete-flow.json
# Deploy!

# 4. Open dashboard
# URL: http://localhost:1880/ui
# âœ… Success!
```

### **ğŸ“ Support:**
- **ğŸ› Issues**: Create GitHub issue vá»›i logs
- **ğŸ’¡ Features**: Submit pull request
- **â“ Questions**: Check troubleshooting guide first

**Happy building! ğŸ‰**

---

**Main File: `final-complete-flow.json` - Contains everything you need! ğŸ¯**
